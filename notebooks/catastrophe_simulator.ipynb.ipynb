{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  🏦 Openly Catastrophe Impact Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "DATA_DIR = '../data/'\n",
    "OUTPUT_DIR = '../data/'\n",
    "\n",
    "print(\"Libraries and paths set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_validate(file, required_cols=None):\n",
    "    \"\"\"Load CSV and validate required columns, report missing, handle errors.\"\"\"\n",
    "    path = os.path.join(DATA_DIR, file)\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if required_cols:\n",
    "            missing = [col for col in required_cols if col not in df.columns]\n",
    "            if missing:\n",
    "                raise ValueError(f\"Missing columns in {file}: {missing}\")\n",
    "        return df\n",
    "    except FileNotFoundError as e:\n",
    "        raise FileNotFoundError(f\"File not found at {path}\") from e\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading {file}: {str(e)}\") from e\n",
    "\n",
    "# Load data (will raise clear errors if missing or malformed)\n",
    "agents = load_and_validate('agents.csv', ['agent_id', 'agent_name', 'region', 'onboarding_date', 'license_type', 'performance_score', 'target_growth'])\n",
    "policies = load_and_validate('policies.csv', ['policy_id', 'agent_id', 'region', 'policy_value', 'premium', 'coverage_type', 'claim_frequency', 'avg_claim_severity', 'reinsurance_coverage', 'inception_date', 'expiry_date'])\n",
    "events = load_and_validate('disaster_events.csv', ['event_id', 'event_type', 'region', 'date', 'severity', 'notes'])\n",
    "print(\"All data loaded and validated.\")\n",
    "\n",
    "# Quick preview\n",
    "display(\n",
    "    agents.head(2),\n",
    "    policies.head(2),\n",
    "    events.head(2)\n",
    ")\n",
    "\n",
    "# Optional: Check for missing values\n",
    "print(\"Missing values check:\")\n",
    "display(\n",
    "    agents.isna().sum(),\n",
    "    policies.isna().sum(),\n",
    "    events.isna().sum()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Catastrophe Impact Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- User Input: Select Event to Simulate ---\n",
    "simulate_event_id = 'E001'  # Default: simulate the first event; override as needed\n",
    "event = events[events['event_id'] == simulate_event_id].iloc[0]\n",
    "print(f\"Simulating Event: {event['event_id']} | {event['event_type']} in {event['region']} (Severity: {event['severity']})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Filter Affected Policies ---\n",
    "region = event['region']\n",
    "affected = policies[policies['region'] == region].copy()\n",
    "if len(affected) == 0:\n",
    "    print(\"WARNING: No policies found in the affected region.\")\n",
    "    print(f\"Region: {region}\")\n",
    "    affected = pd.DataFrame(columns=policies.columns)  # Empty, but keep structure\n",
    "\n",
    "# --- Estimate Payouts ---\n",
    "# Gross payout: policy_value * avg_claim_severity * severity_factor\n",
    "#             (where severity_factor depends on the event severity)\n",
    "severity_factor = 0.25 * event['severity']  # Adjust as needed per business logic\n",
    "affected['gross_payout'] = affected['policy_value'] * affected['avg_claim_severity'] * severity_factor\n",
    "\n",
    "# Net payout after reinsurance: gross_payout * (1 - reinsurance_coverage)\n",
    "affected['net_payout'] = affected['gross_payout'] * (1 - affected['reinsurance_coverage'])\n",
    "\n",
    "# --- Compute Aggregate Metrics ---\n",
    "total_gross = affected['gross_payout'].sum()\n",
    "total_net = affected['net_payout'].sum()\n",
    "reserves = 300_000_000  # Mock total reserves\n",
    "solvency_ratio = reserves / total_net if total_net > 0 else np.inf\n",
    "\n",
    "# --- Print Summary ---\n",
    "print(\"Catastrophe Impact Summary:\")\n",
    "print(f\"Event:           {event['event_type']} in {event['region']}\")\n",
    "print(f\"Date:            {event['date']}\")\n",
    "print(f\"Severity:        {event['severity']}\")\n",
    "print(f\"Policies Impacted:   {len(affected)}\")\n",
    "print(f\"Total Gross Payout:  ${total_gross:,.0f}\")\n",
    "print(f\"Total Net Payout:    ${total_net:,.0f}\")\n",
    "print(f\"Reserve Adequacy (Solvency Ratio): {solvency_ratio:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualization & Business Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not affected.empty:\n",
    "    # --- Policy Payout Distribution ---\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    sns.histplot(affected['gross_payout'], bins=20, kde=True)\n",
    "    plt.title('Gross Payout per Policy ($)')\n",
    "    plt.xlabel('Gross Payout')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    sns.histplot(affected['net_payout'], bins=20, kde=True)\n",
    "    plt.title('Net Payout per Policy (after reinsurance) ($)')\n",
    "    plt.xlabel('Net Payout')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # --- Coverage Type Impact ---\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(\n",
    "        data=affected.groupby('coverage_type')['gross_payout'].sum().reset_index(),\n",
    "        x='coverage_type', y='gross_payout'\n",
    "    )\n",
    "    plt.title('Gross Payout by Coverage Type')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Top Agents by Impact ---\n",
    "    affected_w_agents = affected.merge(agents, on='agent_id', how='left')\n",
    "    top_agents = (\n",
    "        affected_w_agents.groupby('agent_name')['gross_payout'].sum()\n",
    "        .sort_values(ascending=False)\n",
    "        .head(5)\n",
    "        .reset_index()\n",
    "    )\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.barplot(data=top_agents, x='agent_name', y='gross_payout')\n",
    "    plt.title('Top 5 Agents by Gross Payout Impact')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Export for Power BI and Dashboards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Save Detailed Results for Power BI/Dashboard ---\n",
    "affected.to_csv(\n",
    "    os.path.join(OUTPUT_DIR, 'output_catastrophe.csv'),\n",
    "    index=False\n",
    ")\n",
    "print(f\"\\nDetailed results saved to {OUTPUT_DIR}output_catastrophe.csv for Power BI integration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Documentation & Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Sources:**  \n",
    "- `agents.csv`: Agent metadata, 50+ agents.  \n",
    "- `policies.csv`: Policy portfolio, 50+ policies.  \n",
    "- `disaster_events.csv`: Catastrophe log, 50+ events.  \n",
    "\n",
    "**Output:**  \n",
    "- `output_catastrophe.csv`: Per-policy simulation results (gross/net payout, coverage type, agent, region).  \n",
    "\n",
    "**Business Logic:**  \n",
    "- **Gross payout** = policy_value × avg_claim_severity × (0.25 × event_severity)  \n",
    "- **Net payout** = gross_payout × (1.0 - reinsurance_coverage)  \n",
    "- **Solvency ratio** = total_reserves / total_net_payout  \n",
    "\n",
    "**Configurable:**  \n",
    "- Set `simulate_event_id` to any `event_id` from `disaster_events.csv` to simulate alternate scenarios.  \n",
    "- Adjust `severity_factor` formula as needed for your actuarial model.  \n",
    "- `reserves` is arbitrarily set; replace with actual insurer reserve data.  \n",
    "\n",
    "**Reproducible:**  \n",
    "Run for any new event, data refresh, or region. Results are transparent and auditable.  \n",
    "\n",
    "**Ready for Production:**  \n",
    "- Data validation.  \n",
    "- Clear error messages.  \n",
    "- Visuals for executives.  \n",
    "- Export for dashboards (Power BI/Tableau/Looker).  \n",
    "\n",
    "**Next Steps:**  \n",
    "- Batch or parallelize for multiple events.  \n",
    "- Add Monte Carlo simulations for uncertainty.  \n",
    "- Integrate with live catastrophe feeds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Footnotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Adjust** `simulate_event_id` to rerun for different catastrophes.  \n",
    "- **Replace** `reserves` with your actual insurer reserve data when available.  \n",
    "- **Extend** to batch mode per your needs.  \n",
    "- **Power BI:** Connect to `output_catastrophe.csv` for live dashboards.  \n",
    "- **For production:** Schedule with Airflow, GitHub Actions, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
